{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff8d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas necessárias\n",
    "\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b65998f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções gerais do projeto\n",
    "\n",
    "def extract_bans(bans):\n",
    "    if len(bans) == 2:\n",
    "        bans = bans[1].text.strip()\n",
    "    else:\n",
    "        bans = bans[0].text.strip()\n",
    "        \n",
    "    res_dic = {\n",
    "        \"Bans\": [],\n",
    "        \"Picks\": [],\n",
    "    }\n",
    "    \n",
    "    teams_ban = bans.split(\";\")\n",
    "    for ban in teams_ban:\n",
    "        content = ban.strip().split(\" \")\n",
    "        if content[0] == \"C9\":\n",
    "            if content[1] == \"ban\":\n",
    "                res_dic[\"Bans\"].append(content[2])\n",
    "            else:\n",
    "                res_dic[\"Picks\"].append(content[2])\n",
    "    \n",
    "    return res_dic\n",
    "\n",
    "def extract_maps(bans):\n",
    "    if len(bans) == 2:\n",
    "        bans = bans[1].text.strip()\n",
    "    else:\n",
    "        bans = bans[0].text.strip()\n",
    "        \n",
    "    maps = []\n",
    "    \n",
    "    teams_bans = bans.split(\";\")\n",
    "    for ban in teams_bans:\n",
    "        content = ban.strip().split(\" \")\n",
    "        if content[1] == \"pick\":\n",
    "            maps.append(content[2])\n",
    "            \n",
    "        if len(content) == 2:\n",
    "            maps.append(content[0])\n",
    "            \n",
    "    return maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d77a48fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.vlr.gg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dda5903d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Começando análises da Cloud9\n",
    "\n",
    "c9url = \"https://www.vlr.gg/team/matches/188/cloud9\"\n",
    "\n",
    "res = requests.get(c9url)\n",
    "\n",
    "soup = bs(res.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e95ac7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Escolhendo jogos apenas do VCT Americas (mais recente)\n",
    "\n",
    "matches = soup.findAll('a', attrs = {'class': 'wf-card fc-flex m-item'})\n",
    "\n",
    "match_links = []\n",
    "\n",
    "for match in matches:\n",
    "    camp = match.find('div', attrs = {'class': 'text-of'}).text.strip().split(\":\")[0]\n",
    "    if camp == \"VCT 2023\":\n",
    "    \tmatch_links.append(base_url + match.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be75b827",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Entrando em cada jogo e salvando as informações que desejamos em um arquivo json em uma pasta do time\n",
    "\n",
    "c9_games = {}\n",
    "for link in match_links: \n",
    "    r = requests.get(link)\n",
    "    soup = bs(r.text, 'html.parser')\n",
    "    \n",
    "    date = soup.find('div', {'class': 'moment-tz-convert'}).text.strip()\n",
    "    home_team = soup.find('div', {'class': 'match-header-link-name mod-1'}).find_all('div')[0].text.strip()\n",
    "    away_team = soup.find('div', {'class': 'match-header-link-name mod-2'}).find_all('div')[0].text.strip()\n",
    "    \n",
    "    is_c9_away = True\n",
    "    if home_team == \"Cloud9\":\n",
    "        opponent = away_team\n",
    "        is_c9_away = False\n",
    "    else:\n",
    "        opponent = home_team\n",
    "        \n",
    "    print(f\"Raspando informações do jogo: Cloud9 vs {opponent}\")\n",
    "    \n",
    "    bans = soup.find_all('div', attrs = {'class': 'match-header-note'})\n",
    "    c9_bans = extract_bans(bans)\n",
    "    \n",
    "    if home_team == \"Cloud9\":\n",
    "        c9_score = soup.find('div', {'class': 'js-spoiler'}).find_all('span')[0].text.strip()\n",
    "        opponent_score = soup.find('div', {'class': 'js-spoiler'}).find_all('span')[2].text.strip()\n",
    "    else:\n",
    "        c9_score = soup.find('div', {'class': 'js-spoiler'}).find_all('span')[2].text.strip()\n",
    "        opponent_score = soup.find('div', {'class': 'js-spoiler'}).find_all('span')[0].text.strip()\n",
    "    \n",
    "    games = int(c9_score) + int(opponent_score) \n",
    "    first_map_id = int(soup.find('div', {'class': 'vm-stats-gamesnav-item js-map-switch'}).get('data-game-id'))\n",
    "    \n",
    "    maps = extract_maps(bans)\n",
    "    \n",
    "    maps_info = {}\n",
    "    \n",
    "    i = 0\n",
    "    for gid in range(first_map_id, first_map_id+games):\n",
    "        map_info = {}\n",
    "        print(f\"Raspando informações do mapa {maps[i]} com id: {gid}\")\n",
    "        \n",
    "        map_url = f\"{link}/?game={gid}&tab=overview\"\n",
    "        r = requests.get(map_url)\n",
    "        soup = bs(r.text, 'html.parser')\n",
    "        \n",
    "        map_name = soup.find('div', attrs = {'class': 'map'}).find_all('span')[0].text.strip()\n",
    "        \n",
    "        c9_rounds = soup.find('div', attrs = {'class': 'score mod-win'}).text.strip()\n",
    "        opponent_rounds = soup.find('div', attrs = {'class': 'score'}).text.strip()\n",
    "        \n",
    "        tables = soup.find_all('table', {'class': 'wf-table-inset mod-overview'})\n",
    "        \n",
    "        if is_c9_away:\n",
    "            team = tables[1].find('tbody')\n",
    "        else:\n",
    "            team = tables[0].find('tbody')\n",
    "        \n",
    "        for tr in team.find_all('tr'):\n",
    "            player = tr.find('td', attrs = {'class': 'mod-player'}).find('div', attrs = {'class': 'text-of'}).text.strip()\n",
    "            agent = tr.find('td', attrs = {'class': 'mod-agents'}).find('img').get('title')\n",
    "            map_info[player] = agent\n",
    "            \n",
    "        maps_info[maps[i]] = map_info\n",
    "        \n",
    "        i+=1\n",
    "        time.sleep(1)\n",
    "        \n",
    "    c9_games[f\"cloud9-{opponent.lower().replace('á', 'a')}\"] = maps_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5bb0ae58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando as informações da C9\n",
    "\n",
    "with open(\"cloud9.json\", \"w\") as f:\n",
    "    json.dump(c9_games, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddac5f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análises da Leviatán\n",
    "\n",
    "c9url = \"https://www.vlr.gg/team/matches/2359/leviat-n/\"\n",
    "\n",
    "res = requests.get(c9url)\n",
    "\n",
    "soup = bs(res.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d882075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escolhendo jogos apenas do VCT Americas (mais recente)\n",
    "\n",
    "matches = soup.findAll('a', attrs = {'class': 'wf-card fc-flex m-item'})\n",
    "\n",
    "match_links = []\n",
    "\n",
    "for match in matches:\n",
    "    camp = match.find('div', attrs = {'class': 'text-of'}).text.strip().split(\":\")[0]\n",
    "    if camp == \"VCT 2023\":\n",
    "    \tmatch_links.append(base_url + match.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e78db0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raspando informações do jogo: Leviatán vs Cloud9\n",
      "Raspando informações do mapa Lotus com id: 119040\n",
      "Raspando informações do mapa Haven com id: 119041\n",
      "Raspando informações do jogo: Leviatán vs KRÜ Esports\n",
      "Raspando informações do mapa Haven com id: 119022\n",
      "Raspando informações do mapa Split com id: 119023\n",
      "Raspando informações do jogo: Leviatán vs Evil Geniuses\n",
      "Raspando informações do mapa Split com id: 119007\n",
      "Raspando informações do mapa Pearl com id: 119008\n",
      "Raspando informações do mapa Ascent com id: 119009\n",
      "Raspando informações do jogo: Leviatán vs 100 Thieves\n",
      "Raspando informações do mapa Icebox com id: 118986\n",
      "Raspando informações do mapa Haven com id: 118987\n",
      "Raspando informações do mapa Lotus com id: 118988\n",
      "Raspando informações do jogo: Leviatán vs MIBR\n",
      "Raspando informações do mapa Pearl com id: 118971\n",
      "Raspando informações do mapa Icebox com id: 118972\n",
      "Raspando informações do jogo: Leviatán vs Sentinels\n",
      "Raspando informações do mapa Split com id: 118959\n",
      "Raspando informações do mapa Ascent com id: 118960\n",
      "Raspando informações do mapa Pearl com id: 118961\n",
      "Raspando informações do jogo: Leviatán vs FURIA\n",
      "Raspando informações do mapa Pearl com id: 118941\n",
      "Raspando informações do mapa Icebox com id: 118942\n",
      "Raspando informações do mapa Ascent com id: 118943\n",
      "Raspando informações do jogo: Leviatán vs NRG Esports\n",
      "Raspando informações do mapa Pearl com id: 118935\n",
      "Raspando informações do mapa Lotus com id: 118936\n"
     ]
    }
   ],
   "source": [
    "# Entrando em cada jogo e salvando as informações que desejamos em um arquivo json em uma pasta do time\n",
    "\n",
    "lev_games = {}\n",
    "for link in match_links: \n",
    "    r = requests.get(link)\n",
    "    soup = bs(r.text, 'html.parser')\n",
    "    \n",
    "    date = soup.find('div', {'class': 'moment-tz-convert'}).text.strip()\n",
    "    home_team = soup.find('div', {'class': 'match-header-link-name mod-1'}).find_all('div')[0].text.strip()\n",
    "    away_team = soup.find('div', {'class': 'match-header-link-name mod-2'}).find_all('div')[0].text.strip()\n",
    "    \n",
    "    is_lev_away = True\n",
    "    if home_team == \"Leviatán\":\n",
    "        opponent = away_team\n",
    "        is_lev_away = False\n",
    "    else:\n",
    "        opponent = home_team\n",
    "        \n",
    "    print(f\"Raspando informações do jogo: Leviatán vs {opponent}\")\n",
    "    \n",
    "    bans = soup.find_all('div', attrs = {'class': 'match-header-note'})\n",
    "    lev_bans = extract_bans(bans)\n",
    "    \n",
    "    if home_team == \"Leviatán\":\n",
    "        lev_score = soup.find('div', {'class': 'js-spoiler'}).find_all('span')[0].text.strip()\n",
    "        opponent_score = soup.find('div', {'class': 'js-spoiler'}).find_all('span')[2].text.strip()\n",
    "    else:\n",
    "        lev_score = soup.find('div', {'class': 'js-spoiler'}).find_all('span')[2].text.strip()\n",
    "        opponent_score = soup.find('div', {'class': 'js-spoiler'}).find_all('span')[0].text.strip()\n",
    "    \n",
    "    games = int(lev_score) + int(opponent_score) \n",
    "    first_map_id = int(soup.find('div', {'class': 'vm-stats-gamesnav-item js-map-switch'}).get('data-game-id'))\n",
    "    \n",
    "    maps = extract_maps(bans)\n",
    "    \n",
    "    maps_info = {}\n",
    "    \n",
    "    i = 0\n",
    "    for gid in range(first_map_id, first_map_id+games):\n",
    "        map_info = {}\n",
    "        print(f\"Raspando informações do mapa {maps[i]} com id: {gid}\")\n",
    "        \n",
    "        map_url = f\"{link}/?game={gid}&tab=overview\"\n",
    "        r = requests.get(map_url)\n",
    "        soup = bs(r.text, 'html.parser')\n",
    "        \n",
    "        map_name = soup.find('div', attrs = {'class': 'map'}).find_all('span')[0].text.strip()\n",
    "        \n",
    "        lev_rounds = soup.find('div', attrs = {'class': 'score mod-win'}).text.strip()\n",
    "        opponent_rounds = soup.find('div', attrs = {'class': 'score'}).text.strip()\n",
    "        \n",
    "        tables = soup.find_all('table', {'class': 'wf-table-inset mod-overview'})\n",
    "        \n",
    "        if is_lev_away:\n",
    "            team = tables[1].find('tbody')\n",
    "        else:\n",
    "            team = tables[0].find('tbody')\n",
    "        \n",
    "        for tr in team.find_all('tr'):\n",
    "            player = tr.find('td', attrs = {'class': 'mod-player'}).find('div', attrs = {'class': 'text-of'}).text.strip()\n",
    "            agent = tr.find('td', attrs = {'class': 'mod-agents'}).find('img').get('title')\n",
    "            map_info[player] = agent\n",
    "            \n",
    "        maps_info[maps[i]] = map_info\n",
    "        \n",
    "        i+=1\n",
    "        time.sleep(1)\n",
    "        \n",
    "    lev_games[f\"leviatan-{opponent.lower().replace('ü', 'u')}\"] = maps_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54ee04bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando as informações da LEV\n",
    "\n",
    "with open(\"leviatan.json\", \"w\") as f:\n",
    "    json.dump(lev_games, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b39aa40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
